<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.0.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Understanding the Mathematics behind Gradient DescentA simple mathematical intuition behind one of the commonly used optimisation algorithms in Machine Learning.  “Premature optimization is the root o">
<meta name="keywords" content="机器学习,人工智能,AI">
<meta property="og:type" content="article">
<meta property="og:title" content="Understanding the Mathematics behind Gradient Descent">
<meta property="og:url" content="https://www.jacklee.work/人工智能/2019-03-28-Understanding the Mathematics behind Gradient Descent.html">
<meta property="og:site_name" content="JackLee">
<meta property="og:description" content="Understanding the Mathematics behind Gradient DescentA simple mathematical intuition behind one of the commonly used optimisation algorithms in Machine Learning.  “Premature optimization is the root o">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*4VbVds8vD-CgAiOWTrs_Vw.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*ZEIXhLHr99IK7qVSZJlyJg.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*FevGteEfXxQ6nUFiqgSN4A.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*y0ME9Nfr962OLad60mpfiw.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*6bTrn65AGt01MwoYTkvLMw.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*ItujOVbVS683btoMNcSrWw.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*wOcqaaLlNo7X56PJ-lYFqQ.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*C8YyXxRnpyKJuyUUFPNjag.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*LHfPH8izBeLiN3BucwDofg.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*vKWlgvHgO6Yl_c2PYuSGPQ.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*9C5uOCz9-biIz8ynLauQOg.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*lx58ZcrrILLX6I-ZCDN93w.gif">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*YsjwGDKD2JzM5KYuAAeNYg.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*e6Epzbmngh2a50WUrKleUA.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*pEVVCEGBgnUp9n_GFtnoCA.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*2HHOcNqN2IB3Hn0NwjKofQ.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*bA3RTXbN36FITpwpHKDHdA.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*wFNHPg59MDlY2FV4CEPwNw.png">
<meta property="og:image" content="https://www.jacklee.work/assets/images/1*H4W0YR1jVTWyQboPnSZPjQ.png">
<meta property="og:updated_time" content="2019-03-28T09:29:42.414Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Understanding the Mathematics behind Gradient Descent">
<meta name="twitter:description" content="Understanding the Mathematics behind Gradient DescentA simple mathematical intuition behind one of the commonly used optimisation algorithms in Machine Learning.  “Premature optimization is the root o">
<meta name="twitter:image" content="https://www.jacklee.work/assets/images/1*4VbVds8vD-CgAiOWTrs_Vw.png">






  <link rel="canonical" href="https://www.jacklee.work/人工智能/2019-03-28-Understanding the Mathematics behind Gradient Descent.html">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Understanding the Mathematics behind Gradient Descent | JackLee</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JackLee</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">专注,深入,折腾,热爱生活,</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.jacklee.work/人工智能/2019-03-28-Understanding the Mathematics behind Gradient Descent.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JackLee">
      <meta itemprop="description" content="自由泳宇宙顶尖高手">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JackLee">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Understanding the Mathematics behind Gradient Descent

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-28 16:55:19 / 修改时间：17:29:42" itemprop="dateCreated datePublished" datetime="2019-03-28T16:55:19+08:00">2019-03-28</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/人工智能/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/人工智能/2019-03-28-Understanding the Mathematics behind Gradient Descent.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/人工智能/2019-03-28-Understanding the Mathematics behind Gradient Descent.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/人工智能/2019-03-28-Understanding the Mathematics behind Gradient Descent.html" class="leancloud_visitors" data-flag-title="Understanding the Mathematics behind Gradient Descent">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Understanding-the-Mathematics-behind-Gradient-Descent"><a href="#Understanding-the-Mathematics-behind-Gradient-Descent" class="headerlink" title="Understanding the Mathematics behind Gradient Descent"></a>Understanding the Mathematics behind Gradient Descent</h2><p>A simple mathematical intuition behind one of the commonly used optimisation algorithms in Machine Learning.</p>
<blockquote>
<p>“Premature optimization is the root of all evil.”<br>― Donald Ervin Knuth</p>
</blockquote>
<p><a href="http://en.wikipedia.org/wiki/Agile_software_development" target="_blank" rel="noopener"><strong>Agile</strong></a> is a pretty well-known term in the software development process. The basic idea behind it is simple: build something quickly ➡️ get it out there ➡️ get some feedback ➡️ make changes depending upon the feedback ➡️ repeat the process. The <strong>goal</strong> is to get the product near the user and let the user guide you with the <strong>feedback</strong> to obtain the best possible product with the <strong>least error</strong>. Also, the <strong>steps</strong> taken for improvement need to be small and should constantly involve the user. In a way, an Agile software development process involves rapid iterations. The idea of — start with a solution as soon as possible, measure and iterate as frequently as possible, is basically <a href="https://hackernoon.com/life-is-gradient-descent-880c60ac1be8" target="_blank" rel="noopener">Gradient descen</a>t under the hood.</p>
<hr>
<h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3><p>Gradient descent algorithm is an iterative process that takes us to the minimum of a function(barring some caveats). The formula below sums up the entire Gradient Descent algorithm in a single line.</p>
<p><img src="../assets/images/1*4VbVds8vD-CgAiOWTrs_Vw.png" alt="img"></p>
<p>​                    <a href="https://www.coursehero.com/file/27927651/Gradient-Descentpdf/" target="_blank" rel="noopener">https://www.coursehero.com/file/27927651/Gradient-Descentpdf/</a></p>
<p>But how do we arrive at this formula? Well, It is actually very simple and just includes some high school maths. Through this article, we shall try to understand as well as recreate this formula in the context of a Linear Regression model.</p>
<hr>
<h3 id="A-Machine-Learning-Model"><a href="#A-Machine-Learning-Model" class="headerlink" title="A Machine Learning Model"></a>A Machine Learning Model</h3><ul>
<li>Consider a bunch of data points in a 2 D space. Assume that the data is related to the height and weight of a group of students. We are trying to predict some kind of relationship between these quantities so that we could predict the weight of some new students afterwards. This is essentially a simple example of a supervised Machine Learning technique.</li>
<li>Let us now draw an arbitrary line in space that passes through some of these data points. The equation of this straight line would be <code>**Y = mX + b**</code>where <strong>m</strong> is the slope and <strong>b</strong> is its intercept on the Y-axis.</li>
</ul>
<p><img src="../assets/images/1*ZEIXhLHr99IK7qVSZJlyJg.png" alt="img"></p>
<h4 id="Predictions"><a href="#Predictions" class="headerlink" title="Predictions"></a>Predictions</h4><p>Given a known set of inputs and their corresponding outputs, A machine learning model tries to make some predictions for a new set of inputs.</p>
<p><img src="../assets/images/1*FevGteEfXxQ6nUFiqgSN4A.png" alt="img"></p>
<p>ML process</p>
<p>The Error would be the difference between the two predictions.</p>
<p>This relates to the idea of a <strong>Cost function or Loss function.</strong></p>
<hr>
<h3 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h3><p>A <strong>Cost Function/Loss Function</strong> evaluates the performance of our Machine Learning Algorithm. The <strong>Loss function</strong> computes the error for a single training example while the <strong>Cost functi</strong>on is the average of the loss functions for all the training examples. Henceforth, I shall be using both the terms interchangeably.</p>
<blockquote>
<p>A Cost function basically tells us ‘ how good’ our model is at making predictions for a given value of m and b.</p>
</blockquote>
<p>Let’s say, there are a total of ’N’ points in the dataset and for all those ’N’ data points we want to minimize the error. So the Cost function would be the total squared error i.e</p>
<p><img src="../assets/images/1*y0ME9Nfr962OLad60mpfiw.png" alt="img"></p>
<p>Cost function for N data points</p>
<blockquote>
<p>Why do we take the squared differences and simply not the absolute differences? Because the squared differences make it easier to derive a regression line. Indeed, to find that line we need to compute the first derivative of the Cost function, and it is much harder to compute the derivative of absolute values than squared values. Also, the squared differences increase the error distance, thus, making the bad predictions more pronounced than the good ones.</p>
</blockquote>
<h4 id="Minimizing-the-Cost-Function"><a href="#Minimizing-the-Cost-Function" class="headerlink" title="Minimizing the Cost Function"></a>Minimizing the Cost Function</h4><blockquote>
<p>The goal of any Machine Learning Algorithm is to minimize the Cost Function.</p>
</blockquote>
<p>This is because a lower error between the actual and the predicted values signifies that the algorithm has done a good job in learning. Since we want the lowest error value, we want those‘ <strong>m’</strong> and ‘<strong>b’</strong> values which give the smallest possible error.</p>
<h4 id="How-do-we-actually-minimize-any-function"><a href="#How-do-we-actually-minimize-any-function" class="headerlink" title="How do we actually minimize any function?"></a>How do we actually minimize any function?</h4><p>If we look carefully, our <strong>Cost function</strong> is of the form <code>**Y = X²**</code>. In a Cartesian coordinate system, this is an equation for a parabola and can be graphically represented as :</p>
<p><img src="../assets/images/1*6bTrn65AGt01MwoYTkvLMw.png" alt="img"></p>
<p>Parabola</p>
<p>To minimise the function above, we need to find <strong>that value of</strong> <code>**X**</code> <strong>that produces the lowest value of</strong> <code>**Y**</code>which is the <strong>red dot.</strong> It is quite easy to locate the minima here since it is a 2D graph but this may not always be the case especially in case of higher dimensions. For those cases, we need to devise an algorithm to locate the minima, and that algorithm is called<strong>Gradient Descent.</strong></p>
<hr>
<h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><p><strong>Gradient descent</strong> is one of the most popular algorithms to perform optimization and by far the most common way to optimize neural networks. It is an iterative optimisation algorithm used to find the minimum value for a function.</p>
<h4 id="Intuition"><a href="#Intuition" class="headerlink" title="Intuition"></a>Intuition</h4><p>Consider that you are walking along the graph below, and you are currently at the ‘<strong>green</strong>’ dot. Your aim is to reach the minimum i.e the ‘red’ dot, but from your position, you are unable to view it.</p>
<p><img src="../assets/images/1*ItujOVbVS683btoMNcSrWw.png" alt="img"></p>
<p>Figure 2</p>
<p><strong>Possible actions would be:</strong></p>
<ul>
<li>You might go upward or downward</li>
<li>If you decide on which way to go, you might take a bigger step or a little step to reach your destination.</li>
</ul>
<blockquote>
<p>Essentially, there are two things that you should know to reach the minima, i.e. which way to go and how big a step to take.</p>
</blockquote>
<p>Gradient Descent Algorithm helps us to make these decisions efficiently and effectively with the use of derivatives. A <strong>derivative</strong> is a term that comes from calculus and is calculated as the slope of the graph at a particular point. The slope is described by drawing a tangent line to the graph at the point. So, if we are able to compute this tangent line, we might be able to compute the desired direction to reach the minima. We will talk about this in more detail in the later part of the article.</p>
<h4 id="The-Minimum-Value"><a href="#The-Minimum-Value" class="headerlink" title="The Minimum Value"></a>The Minimum Value</h4><p>In the same figure, if we draw a tangent at the green point, we know that if we are moving upwards, we are moving away from the minima and vice versa. Also, the tangent gives us a sense of the steepness of the slope.</p>
<p><img src="../assets/images/1*wOcqaaLlNo7X56PJ-lYFqQ.png" alt="img"></p>
<p>The slope at the blue point is less steep than that at the green point which means it will take much smaller <strong>steps</strong> to reach the minimum from the blue point than from the green point.</p>
<hr>
<h4 id="Mathematical-Interpretation-of-Cost-Function"><a href="#Mathematical-Interpretation-of-Cost-Function" class="headerlink" title="Mathematical Interpretation of Cost Function"></a>Mathematical Interpretation of Cost Function</h4><p>Let us now put all these learnings into a mathematical formula. In the equation, <code>y = mX+b</code>, ‘m’ and ‘b’ are its parameters. During the training process, there will be a small change in their values. Let that small change be denoted by δ<strong>.</strong> The value of parameters will be updated as <strong>m=m-δm</strong><code></code>and<strong>b=b-δb</strong> respectively. Our aim here is to find those values of m and b in<code>y = mx+b</code> , for which the error is minimum i.e values which minimize the cost function.</p>
<p>Rewriting the cost function:</p>
<p><img src="../assets/images/1*C8YyXxRnpyKJuyUUFPNjag.png" alt="img"></p>
<blockquote>
<p>The idea is that by being able to compute the derivative/slope of the function, we can find the minimum of a function.</p>
</blockquote>
<hr>
<h3 id="The-Learning-rate"><a href="#The-Learning-rate" class="headerlink" title="The Learning rate"></a>The Learning rate</h3><p>This size of steps taken to reach the minimum or bottom is called <strong>Learning Rate</strong>. We can cover more area with larger steps/higher learning rate but are at the risk of overshooting the minima. On the other hand, small steps/smaller learning rates will consume a lot of time to reach the lowest point.</p>
<p>The visualisations below give an idea about the Learning Rate concept. <strong>See how in the third figure, we reach the minimum point with the minimum number of steps. This is the optimum learning rate for this problem.</strong></p>
<p><img src="../assets/images/1*LHfPH8izBeLiN3BucwDofg.png" alt="img"><img src="../assets/images/1*vKWlgvHgO6Yl_c2PYuSGPQ.png" alt="img"><img src="../assets/images/1*9C5uOCz9-biIz8ynLauQOg.png" alt="img"></p>
<p>​                    <a href="https://developers.google.com/machine-learning/crash-course/fitter/graph" target="_blank" rel="noopener">Source</a></p>
<p>We saw that when the learning rate is too low, it takes a lot of steps to converge. On the other hand, when the learning rate is too high, Gradient Descent fails to reach the minimum as can be seen in the visualisation below.</p>
<p><img src="../assets/images/1*lx58ZcrrILLX6I-ZCDN93w.gif" alt="img"></p>
<p><a href="https://developers.google.com/machine-learning/crash-course/fitter/graph" target="_blank" rel="noopener">Source</a></p>
<p>Experiment with different learning rates by visiting the link below.</p>
<p><a href="https://developers.google.com/machine-learning/crash-course/fitter/graph" target="_blank" rel="noopener"><strong>Optimizing Learning Rate | Machine Learning Crash Course | Google Developers</strong><br><em>Can you reach the minimum more quickly with a higher learning rate? Set a learning rate of 1, and keep hitting STEP…</em>developers.google.com</a></p>
<hr>
<h3 id="Derivatives"><a href="#Derivatives" class="headerlink" title="Derivatives"></a>Derivatives</h3><p>Machine learning uses derivatives in optimization problems. Optimization algorithms like <em>gradient descent</em> use derivates to actually decide whether to increase or decrease the weights in order to increase or decrease any objective function.</p>
<blockquote>
<p>If we are able to compute the derivative of a function, we know in which direction to proceed to minimize it.</p>
</blockquote>
<p>Primarily we shall be dealing with two concepts from calculus :</p>
<ul>
<li><strong>Power Rule</strong></li>
</ul>
<p>Power rule calculates the derivative of a variable raised to a power.</p>
<p><img src="../assets/images/1*YsjwGDKD2JzM5KYuAAeNYg.png" alt="img"></p>
<ul>
<li><strong>Chain Rule</strong></li>
</ul>
<p>The <strong>chain rule</strong> is used for calculating the derivative of composite functions. The chain rule can also be expressed in <a href="https://en.wikipedia.org/wiki/Leibniz%27s_notation" target="_blank" rel="noopener">Leibniz’s notation</a> as follows:</p>
<p>If a variable <strong>z</strong> depends on the variable <strong>y</strong>, which itself depends on the variable <strong>x</strong>, so that <em>y</em> and <em>z</em> are dependent variables, then <em>z</em>, via the intermediate variable of <em>y</em>, depends on <em>x</em> as well. This is called the <a href="https://en.wikipedia.org/wiki/Chain_rule" target="_blank" rel="noopener">chain rule</a> and is mathematically written as,</p>
<p>Let us understand it through an example:</p>
<p><img src="../assets/images/1*e6Epzbmngh2a50WUrKleUA.png" alt="img"></p>
<ul>
<li>Using the <strong>Power</strong> and <strong>Chain</strong> Rule for derivatives, let’s calculate how Cost function changes relative to m and c. This deals with the concept of <strong>partial derivatives</strong> which says that if there is a function of two variables, then to find the partial derivative of that function w.r.t to one variable, treat the other variable as constant. This will be more clear with an example:</li>
</ul>
<p><img src="../assets/images/1*pEVVCEGBgnUp9n_GFtnoCA.png" alt="img"></p>
<h4 id="Calculating-Gradient-Descent"><a href="#Calculating-Gradient-Descent" class="headerlink" title="Calculating Gradient Descent"></a>Calculating Gradient Descent</h4><p>Let us now apply the knowledge of these rules of calculus in our original equation and find the derivative of the Cost Function w.r.t to both <strong>‘m’</strong> and <strong>‘b’</strong>. Revising the Cost Function equation :</p>
<p>For simplicity, let us get rid of the summation sign. The summation part is important, especially with the concept of <strong>Stochastic gradient descent (SGD )</strong> vs <strong>batch gradient descent</strong>. During the <strong>batch gradient descent</strong>, we look at the error of all the training examples at once while in the <strong>SGD</strong> we look at each error at a time. However, just to keep things simple, we will assume that we are looking at each error one at a time.</p>
<p><img src="../assets/images/1*2HHOcNqN2IB3Hn0NwjKofQ.png" alt="img"></p>
<p>Now let’s calculate the gradient of Error w.r.t to both m and b :</p>
<p><img src="../assets/images/1*bA3RTXbN36FITpwpHKDHdA.png" alt="img"></p>
<p>Plugging the values back in the cost function and multiplying it with the learning rate:</p>
<p><img src="../assets/images/1*wFNHPg59MDlY2FV4CEPwNw.png" alt="img"></p>
<p>Now, this <strong>2</strong> in this equation isn’t that significant since it just says that we have a learning rate twice as big or half as big. So let’s just get rid of it too. So, Ultimately, this entire article boils down to two simple equations which represent the equations for Gradient Descent.</p>
<p><img src="../assets/images/1*H4W0YR1jVTWyQboPnSZPjQ.png" alt="img"></p>
<p>m¹,b¹ = next position parameters; m⁰,b⁰ = current position parameters</p>
<blockquote>
<p>Hence,to solve for the gradient, we iterate through our data points using our new m and b values and compute the partial derivatives. This new gradient tells us the slope of our cost function at our current position and the direction we should move to update our parameters. The size of our update is controlled by the learning rate.</p>
</blockquote>
<hr>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>The point of this article was to demonstrate the concept of gradient descent. We used gradient descent as our optimization strategy for linear regression. by drawing the line of best fit to measure the relationship between student heights and weights. However, it is important to note here that the linear regression example has been chosen for simplicity but can be used with other Machine Learning techniques too.</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习-人工智能-AI/" rel="tag"># 机器学习,人工智能,AI</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div class="social_share">
            
            
              <div id="needsharebutton-postbottom">
                <span class="btn">
                  <i class="fa fa-share-alt" aria-hidden="true"></i>
                </span>
              </div>
            
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/想法/2019-03-05-远程智能儿童监控系统.html" rel="next" title="远程儿童监控系统">
                <i class="fa fa-chevron-left"></i> 远程儿童监控系统
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/操作记录/2019-06-09-Set up the ladder.html" rel="prev" title="Set up the ladder">
                Set up the ladder <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="JackLee">
            
              <p class="site-author-name" itemprop="name">JackLee</p>
              <p class="site-description motion-element" itemprop="description">自由泳宇宙顶尖高手</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">20</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/lijiahua" title="GitHub &rarr; https://github.com/lijiahua" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:jackleeforce@gmail.com" title="E-Mail &rarr; mailto:jackleeforce@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Understanding-the-Mathematics-behind-Gradient-Descent"><span class="nav-number">1.</span> <span class="nav-text">Understanding the Mathematics behind Gradient Descent</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Objective"><span class="nav-number">1.1.</span> <span class="nav-text">Objective</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Machine-Learning-Model"><span class="nav-number">1.2.</span> <span class="nav-text">A Machine Learning Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Predictions"><span class="nav-number">1.2.1.</span> <span class="nav-text">Predictions</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cost-Function"><span class="nav-number">1.3.</span> <span class="nav-text">Cost Function</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Minimizing-the-Cost-Function"><span class="nav-number">1.3.1.</span> <span class="nav-text">Minimizing the Cost Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#How-do-we-actually-minimize-any-function"><span class="nav-number">1.3.2.</span> <span class="nav-text">How do we actually minimize any function?</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradient-Descent"><span class="nav-number">1.4.</span> <span class="nav-text">Gradient Descent</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Intuition"><span class="nav-number">1.4.1.</span> <span class="nav-text">Intuition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Minimum-Value"><span class="nav-number">1.4.2.</span> <span class="nav-text">The Minimum Value</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mathematical-Interpretation-of-Cost-Function"><span class="nav-number">1.4.3.</span> <span class="nav-text">Mathematical Interpretation of Cost Function</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Learning-rate"><span class="nav-number">1.5.</span> <span class="nav-text">The Learning rate</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Derivatives"><span class="nav-number">1.6.</span> <span class="nav-text">Derivatives</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Calculating-Gradient-Descent"><span class="nav-number">1.6.1.</span> <span class="nav-text">Calculating Gradient Descent</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conclusion"><span class="nav-number">1.7.</span> <span class="nav-text">Conclusion</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JackLee</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>








        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=7.0.0"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.0"></script>
<script src="/js/src/post-details.js?v=7.0.0"></script>



  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>



  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: true,
    notify: true,
    appId: 'G1YbJueC49tfw4JS3cb37xdA-gzGzoHsz',
    appKey: 'AyTKiuhas070qOdPPMv98khk',
    placeholder: '',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true
  });
</script>




  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: "AMS"
      }
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
      for (i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
  overflow: auto hidden;
}
</style>

    
  


  

  

  

  
  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>
  <script>
    
      pbOptions = {};
      
        pbOptions.iconStyle = "default";
      
        pbOptions.boxForm = "horizontal";
      
        pbOptions.position = "bottomCenter";
      
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
      flOptions = {};
      
        flOptions.iconStyle = "default";
      
        flOptions.boxForm = "horizontal";
      
        flOptions.position = "middleRight";
      
        flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>


  

  

  

  

  

  

</body>
</html>
